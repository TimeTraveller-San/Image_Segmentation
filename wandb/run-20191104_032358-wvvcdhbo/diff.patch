diff --git a/train.py b/train.py
index eed4674..9d4c8ca 100644
--- a/train.py
+++ b/train.py
@@ -24,12 +24,14 @@ from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingL
 import albumentations as albu
 import configparser
 import argparse
+import wandb
 
 # Catalyst is amazing.
 from catalyst.data import Augmentor
 from catalyst.dl import utils
 from catalyst.data.reader import ImageReader, ScalarReader, ReaderCompose, LambdaReader
-from catalyst.dl.runner import SupervisedRunner
+# from catalyst.dl.runner import SupervisedRunner
+from catalyst.dl.runner import SupervisedWandbRunner as SupervisedRunner
 from catalyst.contrib.models.segmentation import Unet
 from catalyst.dl.callbacks import DiceCallback, EarlyStoppingCallback, InferCallback, CheckpointCallback
 
@@ -94,6 +96,8 @@ def get_model(encoder='resnet18', classes=4):
 
 
 if __name__ == "__main__":
+    wandb.init(project="segmentation-phase2")
+
     config = configparser.ConfigParser()
     config.read('configs/config.ini')
     conf = config['DEFAULT']
@@ -109,6 +113,7 @@ if __name__ == "__main__":
 
     train_ids, valid_ids = get_ids()
     model, preprocessing_fn = get_model(encoder)
+    wandb.watch(model)
     loaders = get_loaders(bs, num_workers, preprocessing_fn)
 
     optimizer = torch.optim.Adam([
@@ -130,7 +135,7 @@ if __name__ == "__main__":
         optimizer=optimizer,
         scheduler=scheduler,
         loaders=loaders,
-        callbacks=[
+        callbacks=[DiceCallback(),
                    EarlyStoppingCallback(patience=5, min_delta=0.001)
                    ],
         logdir=logdir,
