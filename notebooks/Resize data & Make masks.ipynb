{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import collections\n",
    "import time \n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "train_on_gpu = True\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "import albumentations as albu\n",
    "\n",
    "from catalyst.data import Augmentor\n",
    "from catalyst.dl import utils\n",
    "from catalyst.data.reader import ImageReader, ScalarReader, ReaderCompose, LambdaReader\n",
    "from catalyst.dl.runner import SupervisedRunner\n",
    "from catalyst.contrib.models.segmentation import Unet\n",
    "from catalyst.dl.callbacks import DiceCallback, EarlyStoppingCallback, InferCallback, CheckpointCallback\n",
    "\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image, mask, original_image=None, original_mask=None, gray=True):\n",
    "    fontsize = 14\n",
    "    class_dict = {0: \"Fish\", 1: \"Flower\", 2: \"Gravel\", 3: \"Sugar\"}    \n",
    "    if original_image is None and original_mask is None:\n",
    "        f, ax = plt.subplots(1, 5, figsize=(24, 24))\n",
    "\n",
    "        if gray:\n",
    "            ax[0].imshow(image, cmap='gray')\n",
    "        else:    \n",
    "            ax[0].imshow(image)\n",
    "        for i in range(4):\n",
    "            ax[i + 1].imshow(mask[:, :, i])\n",
    "            ax[i + 1].set_title(f\"Mask {class_dict[i]}\", fontsize=fontsize)\n",
    "    else:\n",
    "        f, ax = plt.subplots(2, 5, figsize=(24, 12))\n",
    "\n",
    "        ax[0, 0].imshow(original_image)\n",
    "        ax[0, 0].set_title(\"Original image\", fontsize=fontsize)\n",
    "\n",
    "        for i in range(4):\n",
    "            ax[0, i + 1].imshow(original_mask[:, :, i])\n",
    "            ax[0, i + 1].set_title(f\"Original mask {class_dict[i]}\", fontsize=fontsize)\n",
    "\n",
    "        ax[1, 0].imshow(image)\n",
    "        ax[1, 0].set_title(\"Transformed image\", fontsize=fontsize)\n",
    "\n",
    "        for i in range(4):\n",
    "            ax[1, i + 1].imshow(mask[:, :, i])\n",
    "            ax[1, i + 1].set_title(\n",
    "                f\"Transformed mask {class_dict[i]}\", fontsize=fontsize\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(image_path, gray=False):\n",
    "    img = cv2.imread(image_path)\n",
    "    if gray:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = img[:,:,None]\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img \n",
    "\n",
    "def rle_decode(mask_rle: str = \"\", shape: tuple = (1400, 2100)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape, order=\"F\")\n",
    "\n",
    "def make_mask(df: pd.DataFrame, image_name: str='img.jpg', shape: tuple = (1400, 2100)):\n",
    "    encoded_masks = df.loc[df['im_id'] == image_name, 'EncodedPixels']\n",
    "    masks = np.zeros((shape[0], shape[1], 4), dtype=np.float32)\n",
    "    for idx, label in enumerate(encoded_masks.values):\n",
    "        if label is not np.nan:\n",
    "            mask = rle_decode(label)\n",
    "            masks[:, :, idx] = mask         \n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 10\n",
    "SEED = 42\n",
    "MODEL_NO = 0\n",
    "path = \"../input/\"\n",
    "train = pd.read_csv(f\"{path}/train.csv\")\n",
    "train[\"label\"] = train[\"Image_Label\"].apply(lambda x: x.split(\"_\")[1])\n",
    "train[\"im_id\"] = train[\"Image_Label\"].apply(lambda x: x.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = '../input/train_images_525/train_images_525/'\n",
    "TRAIN_C = '../input/train_images_480/'\n",
    "TRAIN_C_M = '../input/train_masks_480/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5546/5546 [08:43<00:00, 10.59it/s, file=bbde96d.jpg]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if not os.path.exists(TRAIN_C):\n",
    "    os.makedirs(TRAIN_C)\n",
    "    \n",
    "if not os.path.exists(TRAIN_C_M):\n",
    "    os.makedirs(TRAIN_C_M)\n",
    "    \n",
    "from tqdm import tqdm \n",
    "\n",
    "# Resize and save train images and masks\n",
    "tfms = albu.Compose([albu.Resize(320, 480)])\n",
    "bar = tqdm(os.listdir(TRAIN), postfix={\"file\":\"none\"})\n",
    "\n",
    "for file in bar:\n",
    "    bar.set_postfix(ordered_dict={\"file\":file})    \n",
    "    path = os.path.join(TRAIN, file)\n",
    "    img = get_img(path)    \n",
    "    mask = make_mask(train, file) \n",
    "    tfmed = tfms(image=img, mask=mask)\n",
    "    img = tfmed['image']\n",
    "    mask = tfmed['mask']\n",
    "    np.save(os.path.join(TRAIN_C_M, file), mask)\n",
    "    np.save(os.path.join(TRAIN_C, file), img) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(350, 525, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_img(fname, folder=\"../input/train_images_525/train_images_525\", npy=False):\n",
    "    if npy:\n",
    "        return np.load(os.path.join(folder, fname+'.npy'))\n",
    "    img = cv2.imread(os.path.join(folder, fname))\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img = get_img('bbde96d.jpg', TRAIN_C, True)\n",
    "print(type(img))\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import albumentations as albu\n",
    "from utils import get_mask\n",
    "from augmentations import get_training_augmentation, get_validation_augmentation, get_preprocessing\n",
    "\"\"\"\n",
    "DataLoader. I have preprocessed and saved masks as images. Also, resized and\n",
    "saved the images. I used someone else's code to decode RLE into masks.\n",
    "\"\"\"\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, ids, transforms, preprocessing=False,\n",
    "            img_db=TRAIN_C,\n",
    "            mask_db=TRAIN_C_M, npy=False):\n",
    "        self.ids = ids\n",
    "        self.transforms = transforms\n",
    "        self.preprocessing = preprocessing\n",
    "        self.img_db = img_db\n",
    "        self.mask_db = mask_db\n",
    "        self.npy = npy\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id = self.ids[idx]\n",
    "        image = get_img(id, self.img_db, self.npy)\n",
    "        mask = get_mask(id, self.mask_db)\n",
    "        augmented = self.transforms(image=image, mask=mask)\n",
    "        image = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "        if self.preprocessing:\n",
    "            pre = self.preprocessing(image=image, mask=mask)\n",
    "            image = pre['image']\n",
    "            mask = pre['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Training dataset for Segmentation task. Returns [img, mask(s)].\"\n",
    "\n",
    "\n",
    "class SegmentationDataset_withid(Dataset):\n",
    "    def __init__(self, ids, transforms, preprocessing=False,\n",
    "            img_db=\"input/train_images_525/train_images_525\",\n",
    "            mask_db=\"input/mask\"):\n",
    "        self.ids = ids\n",
    "        self.transforms = transforms\n",
    "        self.preprocessing = preprocessing\n",
    "        self.img_db = img_db\n",
    "        self.mask_db = mask_db\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id = self.ids[idx]\n",
    "        image = get_img(id, self.img_db)\n",
    "        mask = get_mask(id, self.mask_db)\n",
    "        augmented = self.transforms(image=image, mask=mask)\n",
    "        image = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "        if self.preprocessing:\n",
    "            pre = self.preprocessing(image=image, mask=mask)\n",
    "            image = pre['image']\n",
    "            mask = pre['mask']\n",
    "\n",
    "        return image, mask, id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Training dataset for Segmentation task. Returns [img, mask(s)].\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = lambda x: x\n",
    "train_ids = os.listdir(TRAIN)\n",
    "dataset = SegmentationDataset(ids=train_ids,\n",
    "                    transforms=get_training_augmentation(),\n",
    "                    preprocessing=None,\n",
    "                    img_db=TRAIN_C,\n",
    "                    mask_db=TRAIN_C_M, npy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 525, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "(350, 525, 4)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for x in dataset:\n",
    "    print(x[0].shape)\n",
    "    print(type(x[0]))\n",
    "    print(x[1].shape)\n",
    "    print(type(x[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
