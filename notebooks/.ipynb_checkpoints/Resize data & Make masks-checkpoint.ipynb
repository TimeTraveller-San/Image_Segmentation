{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lz4 not available, disabling compression. To install lz4, run `pip install lz4`.\n",
      "wandb not available, to install wandb, run `pip install wandb`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import collections\n",
    "import time \n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "train_on_gpu = True\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "import albumentations as albu\n",
    "\n",
    "from catalyst.data import Augmentor\n",
    "from catalyst.dl import utils\n",
    "from catalyst.data.reader import ImageReader, ScalarReader, ReaderCompose, LambdaReader\n",
    "from catalyst.dl.runner import SupervisedRunner\n",
    "from catalyst.contrib.models.segmentation import Unet\n",
    "from catalyst.dl.callbacks import DiceCallback, EarlyStoppingCallback, InferCallback, CheckpointCallback\n",
    "\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image, mask, original_image=None, original_mask=None, gray=True):\n",
    "    fontsize = 14\n",
    "    class_dict = {0: \"Fish\", 1: \"Flower\", 2: \"Gravel\", 3: \"Sugar\"}    \n",
    "    if original_image is None and original_mask is None:\n",
    "        f, ax = plt.subplots(1, 5, figsize=(24, 24))\n",
    "\n",
    "        if gray:\n",
    "            ax[0].imshow(image, cmap='gray')\n",
    "        else:    \n",
    "            ax[0].imshow(image)\n",
    "        for i in range(4):\n",
    "            ax[i + 1].imshow(mask[:, :, i])\n",
    "            ax[i + 1].set_title(f\"Mask {class_dict[i]}\", fontsize=fontsize)\n",
    "    else:\n",
    "        f, ax = plt.subplots(2, 5, figsize=(24, 12))\n",
    "\n",
    "        ax[0, 0].imshow(original_image)\n",
    "        ax[0, 0].set_title(\"Original image\", fontsize=fontsize)\n",
    "\n",
    "        for i in range(4):\n",
    "            ax[0, i + 1].imshow(original_mask[:, :, i])\n",
    "            ax[0, i + 1].set_title(f\"Original mask {class_dict[i]}\", fontsize=fontsize)\n",
    "\n",
    "        ax[1, 0].imshow(image)\n",
    "        ax[1, 0].set_title(\"Transformed image\", fontsize=fontsize)\n",
    "\n",
    "        for i in range(4):\n",
    "            ax[1, i + 1].imshow(mask[:, :, i])\n",
    "            ax[1, i + 1].set_title(\n",
    "                f\"Transformed mask {class_dict[i]}\", fontsize=fontsize\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(image_path, gray=False):\n",
    "    img = cv2.imread(image_path)\n",
    "    if gray:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = img[:,:,None]\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img \n",
    "\n",
    "def rle_decode(mask_rle: str = \"\", shape: tuple = (1400, 2100)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape, order=\"F\")\n",
    "\n",
    "\n",
    "\n",
    "def make_mask(df: pd.DataFrame, image_name: str='img.jpg', shape: tuple = (1400, 2100)):\n",
    "    encoded_masks = df.loc[df['im_id'] == image_name, 'EncodedPixels']\n",
    "    masks = np.zeros((shape[0], shape[1], 4), dtype=np.float32)\n",
    "    for idx, label in enumerate(encoded_masks.values):\n",
    "        if label is not np.nan:\n",
    "            mask = rle_decode(label)\n",
    "            masks[:, :, idx] = mask         \n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 10\n",
    "SEED = 42\n",
    "MODEL_NO = 0\n",
    "path = \"../input/\"\n",
    "train = pd.read_csv(f\"{path}/train.csv\")\n",
    "train[\"label\"] = train[\"Image_Label\"].apply(lambda x: x.split(\"_\")[1])\n",
    "train[\"im_id\"] = train[\"Image_Label\"].apply(lambda x: x.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_C = '../input/resized_train/'\n",
    "TRAIN_C_M = '../input/resized_train_masks/'\n",
    "TEST_C = '../input/resized_test/'\n",
    "if not os.path.exists(TRAIN_C):\n",
    "    os.makedirs(TRAIN_C)\n",
    "if not os.path.exists(TEST_C):\n",
    "    os.makedirs(TEST_C) \n",
    "if not os.path.exists(TRAIN_C_M):\n",
    "    os.makedirs(TRAIN_C_M)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = '/home/timetraveller/Entertainment/CloudSatellite-KAGGLE/train_images'\n",
    "TEST = '/home/timetraveller/Entertainment/CloudSatellite-KAGGLE/test_images'\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Resize and save train images and masks\n",
    "tfms = albu.Compose([albu.Resize(320, 640)])\n",
    "bar = tqdm(os.listdir(TRAIN), postfix={\"file\":\"none\"})\n",
    "\n",
    "for file in bar:\n",
    "    bar.set_postfix(ordered_dict={\"file\":file})    \n",
    "    path = os.path.join(TRAIN, file)\n",
    "    img = get_img(path)    \n",
    "    mask = make_mask(train, file) \n",
    "    tfmed = tfms(image=img, mask=mask)\n",
    "    img = tfmed['image']\n",
    "    mask = tfmed['mask']\n",
    "    np.save(os.path.join(TRAIN_C_M, file), mask)\n",
    "    np.save(os.path.join(TRAIN_C, file), img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize and save test images \n",
    "\n",
    "tfms = albu.Compose([albu.Resize(320, 640)])\n",
    "bar = tqdm(os.listdir(TEST), postfix={\"file\":\"none\"})\n",
    "\n",
    "for file in bar:\n",
    "    bar.set_postfix(ordered_dict={\"file\":file})    \n",
    "    path = os.path.join(TEST, file)\n",
    "    img = get_img(path)    \n",
    "    tfmed = tfms(image=img, mask=None)\n",
    "    img = tfmed['image']\n",
    "    np.save(os.path.join(TEST_C, file), img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
